# -*- coding: utf-8 -*-
"""Диплом.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hVRg6ReIGBMhc2UFTOhbq_pnypxTfwWf

Скачивание библиотек
"""

!pip install dlib
!pip install imutils
!pip install menpo
!pip install menpofit
!pip install mtcnn
!pip install ultralytics
!pip install imgaug
!pip install streamlit
!pip install ipywidgets

#!pip install scipy==1.11.0
#!pip install tensorflow==2.15

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import random
import shutil

from mtcnn import MTCNN
import dlib
import imutils
from imgaug import augmenters as iaa

import streamlit as st
import tempfile
import ipywidgets as widgets

import skimage
from skimage import color
from skimage.feature import hog
from skimage import data, exposure, io, color, feature

"""Импорт библиотек

# Сопровождение к теоретической части

## Демонстрация методов

### HOG
"""

image_path = "/content/1.jpg"
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)

orientations = 9
pixels_per_cell = (8, 8)
cells_per_block = (2, 2)

hog_features, hog_image = skimage.feature.hog(image_gray, orientations=orientations,
                                       pixels_per_cell=pixels_per_cell,
                                       cells_per_block=cells_per_block,
                                       visualize=True)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title('Исходное изображение')
plt.imshow(image)
plt.axis('off')

plt.subplot(1, 2, 2)
plt.title('HOG изображение')
plt.imshow(hog_image, cmap='gist_yarg')
plt.axis('off')

plt.show()

"""### Каскад-Хаара"""

image_path = "/content/3.png"
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
faces = face_cascade.detectMultiScale(image_gray, scaleFactor=1.1, minNeighbors=5)

for (x, y, w, h) in faces:
    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)

plt.figure(figsize=(10, 10))
plt.imshow(image)
plt.title('Обнаруженные лица')
plt.axis("off")
plt.show()

"""### LBP"""

image = cv2.imread("/content/2.jpg")
image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
radius = 2
n_points = 10 * radius

lbp = feature.local_binary_pattern(image_gray, n_points, radius, method="uniform")
(h, _) = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3),
                      range=(0, n_points + 2))

h = h.astype("float")
h /= h.sum()
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(lbp, cmap='gray')
plt.title('Local Binary Patterns')
plt.axis("off")

plt.subplot(1, 2, 2)
plt.bar(np.arange(len(h)), h, color='blue', alpha=0.7)
plt.title('Histogram of LBP')
plt.xlabel('LBP Values')
plt.ylabel('Frequency')
plt.tight_layout()
plt.show()

"""### MTCNN"""

def detect_faces(image_path):
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    detector = MTCNN()
    faces = detector.detect_faces(image_rgb)
    for face in faces:
        x, y, width, height = face['box']
        cv2.rectangle(image_rgb, (x, y), (x + width, y + height), (0, 255, 0), 2)
        for key in face['keypoints']:
            cv2.circle(image_rgb, (face['keypoints'][key][0], face['keypoints'][key][1]), 2, (255, 0, 0), 2)

    plt.imshow(image_rgb)
    plt.axis('off')
    plt.show()

image_path = '/content/5.jpg'
detect_faces(image_path)

!pip install mtcnn

from mtcnn import MTCNN

def detect_faces(image_path):
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    detector = MTCNN()
    faces = detector.detect_faces(image_rgb)

"""### ASM"""

predictor_url = 'http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2'
!wget {predictor_url} -O shape_predictor_68_face_landmarks.dat.bz2
!bunzip2 shape_predictor_68_face_landmarks.dat.bz2

detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')

image = cv2.imread('/content/4.png')
image = imutils.resize(image, width=600)
rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
faces = detector(rgb_image)
for face in faces:
    landmarks = predictor(rgb_image, face)
    for n in range(0, 68):
        x = landmarks.part(n).x
        y = landmarks.part(n).y
        cv2.circle(image, (x, y), 2, (0, 255, 0), -1)
        cv2.putText(image, str(n), (x + 5, y + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)

plt.figure(figsize=(10, 10))
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.show()





"""## Обработка изображений

### Аугментация
"""

image_path = '/content/Lana.jpg'
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

seq = iaa.Sequential([
    iaa.Fliplr(0.5),
    iaa.Flipud(0.2),
    iaa.Rotate((-30, 30)),
    iaa.Affine(translate_percent={"x": 0.1, "y": 0.1}),
    iaa.Multiply((1.5, 1)),
    iaa.AdditiveGaussianNoise(scale=(0, 0.1*255)),
    iaa.ContrastNormalization((0.5, 2.0)),
])

images_aug = seq(images=[image])
augmented_image = images_aug[0]

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(image)
plt.title('Исходное изображение')
plt.axis('off')
plt.subplot(1, 2, 2)
plt.imshow(augmented_image)
plt.title('Аугментированное изображение')
plt.axis('off')
plt.tight_layout()
plt.show()

"""### Визуальные атаки"""

# 1. Атака с добавлением белого шума
def add_white_noise(image, mean=0, std=25):
    noise = np.random.normal(mean, std, image.shape).astype(np.uint8)
    noisy_image = cv2.add(image, noise)
    return noisy_image

# 2. Однопиксельная атака
def targeted_attack(image, target_coordinates):
    modified_image = image.copy()
    modified_image[target_coordinates[1], target_coordinates[0]] = (0, 0, 0)
    cv2.circle(modified_image, target_coordinates, radius=10, color=(0, 255, 255), thickness=2)
    return modified_image

# 3. Монохромная атака
def area_attack(image, area_coordinates):
    modified_image = image.copy()
    for x in range(area_coordinates[0][0], area_coordinates[1][0]):
        for y in range(area_coordinates[0][1], area_coordinates[1][1]):
            modified_image[y, x] = (255, 255, 255)  # Белый цвет
    return modified_image

# 4. Бинарная атака в области
def binary_area_attack(image, area_coordinates):
    modified_image = image.copy()
    for x in range(area_coordinates[0][0], area_coordinates[1][0]):
        for y in range(area_coordinates[0][1], area_coordinates[1][1]):
            if random.random() < 0.5:
                modified_image[y, x] = 0   # Черный
            else:
                modified_image[y, x] = 255  # Белый
    return modified_image

image = cv2.imread('/content/9.jpg')
noisy_image = add_white_noise(image)
cv2_imshow(noisy_image)

targeted_image = targeted_attack(image, (200, 500))
cv2_imshow(targeted_image)

area_image = area_attack(image, ((200, 300), (300,500)))
cv2_imshow(area_image)

binary_image = binary_area_attack(image, ((400,300), (600, 500)))
cv2_imshow(binary_image)

"""### Создание дополнительных изображений для обучения"""

input_folder = '/content/drive/MyDrive/датасет диплом/для изменений/шум'
output_folder = '/content/drive/MyDrive/датасет диплом/для изменений/шум_создан'
os.makedirs(output_folder, exist_ok=True)

for filename in os.listdir(input_folder):
    if filename.endswith(('.png', '.jpg', '.jpeg')):
        image_path = os.path.join(input_folder, filename)
        image = cv2.imread(image_path)

        if image is not None:
            noisy_image = add_white_noise(image)
            output_path = os.path.join(output_folder, filename)
            cv2.imwrite(output_path, noisy_image)

input_folder = '/content/drive/MyDrive/датасет диплом/для изменений/квадратики'
output_folder = '/content/drive/MyDrive/датасет диплом/для изменений/квадратики_созданы'
os.makedirs(output_folder, exist_ok=True)

for filename in os.listdir(input_folder):
    if filename.endswith(('.png', '.jpg', '.jpeg')):
        image_path = os.path.join(input_folder, filename)
        image = cv2.imread(image_path)

        if image is not None:
            noisy_image = binary_area_attack(image, ((200,100), (300, 200)))
            output_path = os.path.join(output_folder, filename)
            cv2.imwrite(output_path, noisy_image)

input_folder = '/content/drive/MyDrive/датасет диплом/для изменений/атака + шум'
output_folder = '/content/drive/MyDrive/датасет диплом/для изменений/атака + шум_созданы'
os.makedirs(output_folder, exist_ok=True)

for filename in os.listdir(input_folder):
    if filename.endswith(('.png', '.jpg', '.jpeg', '.PNG')):
        image_path = os.path.join(input_folder, filename)
        image = cv2.imread(image_path)

        if image is not None:
            noisy_image = add_white_noise(image)
            output_path = os.path.join(output_folder, filename)
            cv2.imwrite(output_path, noisy_image)

input_folder = '/content/drive/MyDrive/датасет диплом/для изменений/монохромная атака'
output_folder = '/content/drive/MyDrive/датасет диплом/для изменений/монохромная атака_создана'
os.makedirs(output_folder, exist_ok=True)

for filename in os.listdir(input_folder):
    if filename.endswith(('.png', '.jpg', '.jpeg', '.PNG')):
        image_path = os.path.join(input_folder, filename)
        image = cv2.imread(image_path)

        if image is not None:
            noisy_image = area_attack(image, ((100, 100), (150,160)))
            output_path = os.path.join(output_folder, filename)
            cv2.imwrite(output_path, noisy_image)

"""# Практическая часть"""

!pip install opencv-python
!pip install tensorflow==2.16.1
!pip install keras==3.0.5

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import random
import shutil
import cv2
from PIL import Image


import locale
locale.getpreferredencoding = lambda: "UTF-8"

from glob import glob

from mtcnn import MTCNN

import tensorflow
import tensorflow as tf
from tensorflow import keras
from keras import layers, models
from keras.src.legacy.preprocessing.image import ImageDataGenerator
from keras.utils import load_img, img_to_array
from keras.preprocessing import image
from keras.layers import BatchNormalization, Dense, Flatten, GlobalAveragePooling2D, Conv2D, MaxPooling2D, Dropout
from keras import Sequential
from keras.applications.mobilenet_v2 import MobileNetV2
from keras.callbacks import EarlyStopping
from keras.saving import load_model
from tensorflow.keras.utils import to_categorical

import torch

from sklearn.metrics import classification_report, confusion_matrix
from sklearn.decomposition import PCA

import time
import warnings
warnings.filterwarnings('ignore')

#DATASET_DIR = "C:/Users/Anastasia/Downloads/датасет диплом/Бинарная/"
TRAIN_DIR = "C:/Users/Anastasia/Downloads/Бинарная/train"
VALID_DIR = "C:/Users/Anastasia/Downloads/Бинарная/val"
TEST_DIR = "C:/Users/Anastasia/Downloads/Бинарная/test"

IMG_HEIGHT, IMG_WIDTH = 128, 128
BATCH_SIZE = 32

train_datagen = ImageDataGenerator(rescale=1./255,
                                   rotation_range=20,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True)
validation_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    TRAIN_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='binary')

validation_generator = validation_datagen.flow_from_directory(
    VALID_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='binary')

test_generator = test_datagen.flow_from_directory(
    TEST_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=1, class_mode='binary', shuffle=False)

classes = list(train_generator.class_indices.keys())
classes

faces_folder = "C:/Users/Anastasia/Downloads/Бинарная/train/selfie"
random_objects_folder = "C:/Users/Anastasia/Downloads/Бинарная/train/other"

num_faces = len([f for f in os.listdir(faces_folder)])
num_random_objects = len([f for f in os.listdir(random_objects_folder)])

labels = ['Selfie', 'Other']
sizes = [num_faces, num_random_objects]
colors = ['#ff9999', '#66b3ff']
explode = (0.1, 0)

plt.figure(figsize=(6, 6))
plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)
plt.title('Distribution of Files in Folders')
plt.axis('equal')
plt.show()

print('Количество фотографий с лицами = ', sizes[0])
print('Количество фотографий с другими объектами = ', sizes[1])

"""### VGG16"""

base_model_VGG16 = tf.keras.applications.VGG16(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), weights='imagenet', include_top=False)
base_model_VGG16.trainable = False

model_VGG16 = Sequential([
    base_model_VGG16,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')
])

model_VGG16.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model_VGG16.summary()

start_time = time.time()
EPOCHS = 5
history_2 = model_VGG16.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS
)

elapsed_time = time.time() - start_time
print(f"Время обучения: {elapsed_time} секунд")
test_loss, test_accuracy = model_VGG16.evaluate(test_generator)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")

model_VGG16.save("face_detector_model_VGG16.h5")
model_VGG16.save("face_detector_model_VGG16.keras")

predictions = (model_VGG16.predict(test_generator) > 0.6).astype(int)
true_labels = test_generator.classes

print("Classification Report:")
print(classification_report(true_labels, predictions, target_names=["Other", "Selfie"]))

cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, fmt='d', cmap='Blues', xticklabels=["Other", "Selfie"], yticklabels=["Other", "Selfie"])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

faces_folder = "C:/Users/Anastasia/Downloads/Бинарная/test/selfie"
random_objects_folder = "C:/Users/Anastasia/Downloads/Бинарная/test/other"
test_VGG16 = load_model("face_detector_model_VGG16.keras")

face_images = [f for f in os.listdir(faces_folder) if f.endswith(('png', 'jpg', 'jpeg', '.PNG'))]
random_images = [f for f in os.listdir(random_objects_folder) if f.endswith(('png', 'jpg', 'jpeg', '.PNG'))]

num_images_to_show = 6
sample_faces = random.sample(face_images, num_images_to_show//2)
sample_random_objects = random.sample(random_images, num_images_to_show//2)

test_images = []
test_labels = []

for img_name in sample_random_objects:
    img_path = os.path.join(random_objects_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(0)

for img_name in sample_faces:
    img_path = os.path.join(faces_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(1)

test_images = np.array(test_images)
test_labels = np.array(test_labels)
predictions = (test_VGG16.predict(test_images) > 0.6).astype(int)

plt.figure(figsize=(15, 8))
for i in range(num_images_to_show):
    plt.subplot(1, num_images_to_show, i + 1)
    plt.imshow(test_images[i])

    true_label = test_labels[i]
    predicted_label = predictions[i][0]

    plt.title(f"True: {['Other', 'Selfie'][true_label]}\nPred: {['Other', 'Selfie'][predicted_label]}")
    plt.axis('off')

plt.tight_layout()
plt.show()

def predict_face(image_path, model):
    img = image.load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    #plt.imshow(img)
    #plt.show()
    prediction = model.predict(img_array)[0][0]
    return "Other" if prediction <= 0.6 else "Selfie"

image_folder = "C:/Users/Anastasia/Downloads/Тестирование"
selfie_count = 0

for img_name in os.listdir(image_folder):
    if img_name.endswith(('png', 'jpg', 'jpeg', 'PNG')):
        img_path = os.path.join(image_folder, img_name)
        result = predict_face(img_path, model_test_VGG16)
        if result == "Selfie":
            selfie_count += 1
print(f"Total 'Selfie' predictions: {selfie_count}")



"""### ResNet50"""

base_model_ResNet50 = tf.keras.applications.ResNet50(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), weights='imagenet', include_top=False)
base_model_ResNet50.trainable = False

model_ResNet50 = Sequential([
    base_model_ResNet50,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])


model_ResNet50.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model_ResNet50.summary()

start_time = time.time()
EPOCHS = 10
history = model_ResNet50.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS
)

elapsed_time = time.time() - start_time
print(f"Время обучения: {elapsed_time} секунд")
test_loss, test_accuracy = model_ResNet50.evaluate(test_generator)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")

model_ResNet50.save("model_ResNet50.keras")

predictions = (model_ResNet50.predict(test_generator) > 0.6).astype(int)
true_labels = test_generator.classes

print("Classification Report:")
print(classification_report(true_labels, predictions, target_names=["Other", "Selfie"]))

cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, fmt='d', cmap='Blues', xticklabels=["Other", "Selfie"], yticklabels=["Other", "Selfie"])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

faces_folder = "C:/Users/Anastasia/Downloads/Бинарная/test/selfie"
random_objects_folder = "C:/Users/Anastasia/Downloads/Бинарная/test/other"
model_ResNet50 = load_model("model_ResNet50.keras")

face_images = [f for f in os.listdir(faces_folder) if f.endswith(('png', 'jpg', 'jpeg', '.PNG'))]
random_images = [f for f in os.listdir(random_objects_folder) if f.endswith(('png', 'jpg', 'jpeg', '.PNG'))]

num_images_to_show = 6
sample_faces = random.sample(face_images, num_images_to_show//2)
sample_random_objects = random.sample(random_images, num_images_to_show//2)

test_images = []
test_labels = []

for img_name in sample_random_objects:
    img_path = os.path.join(random_objects_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(0)

for img_name in sample_faces:
    img_path = os.path.join(faces_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(1)

test_images = np.array(test_images)
test_labels = np.array(test_labels)
predictions = (model_ResNet50.predict(test_images) > 0.6).astype(int)

plt.figure(figsize=(15, 8))
for i in range(num_images_to_show):
    plt.subplot(1, num_images_to_show, i + 1)
    plt.imshow(test_images[i])

    true_label = test_labels[i]
    predicted_label = predictions[i][0]

    plt.title(f"True: {['Other', 'Selfie'][true_label]}\nPred: {['Other', 'Selfie'][predicted_label]}")
    plt.axis('off')

plt.tight_layout()
plt.show()

image_folder = "C:/Users/Anastasia/Downloads/Тестирование"
selfie_count = 0

for img_name in os.listdir(image_folder):
    if img_name.endswith(('png', 'jpg', 'jpeg', 'PNG')):
        img_path = os.path.join(image_folder, img_name)
        result = predict_face(img_path, model_ResNet50)
        if result == "Selfie":
            selfie_count += 1
print(f"Total 'Selfie' predictions: {selfie_count}")



"""### MobileNetV2"""

base_model_MobileNetV2 = tf.keras.applications.MobileNetV2(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False, weights='imagenet')
base_model_MobileNetV2.trainable = False

model_MobileNetV2 = Sequential([
    base_model_MobileNetV2,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')
])

model_MobileNetV2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model_MobileNetV2.summary()

start_time = time.time()
EPOCHS = 2
history = model_MobileNetV2.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS
)

elapsed_time = time.time() - start_time
print(f"Время обучения: {elapsed_time} секунд")
test_loss, test_accuracy = model_MobileNetV2.evaluate(test_generator)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")
model_MobileNetV2.save("model_MobileNetV2.keras")

predictions = (model_MobileNetV2.predict(test_generator) > 0.6).astype(int)
true_labels = test_generator.classes

print("Classification Report:")
print(classification_report(true_labels, predictions, target_names=["Other", "Selfie"]))

cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, fmt='d', cmap='Blues', xticklabels=["Other", "Selfie"], yticklabels=["Other", "Selfie"])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

faces_folder = "C:/Users/Anastasia/Downloads/Бинарная/test/selfie"
random_objects_folder = "C:/Users/Anastasia/Downloads/Бинарная/test/other"
model_MobileNetV2 = load_model("model_MobileNetV2.keras")

face_images = [f for f in os.listdir(faces_folder) if f.endswith(('png', 'jpg', 'jpeg', '.PNG'))]
random_images = [f for f in os.listdir(random_objects_folder) if f.endswith(('png', 'jpg', 'jpeg', '.PNG'))]

num_images_to_show = 6
sample_faces = random.sample(face_images, num_images_to_show//2)
sample_random_objects = random.sample(random_images, num_images_to_show//2)

test_images = []
test_labels = []

for img_name in sample_random_objects:
    img_path = os.path.join(random_objects_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(0)

for img_name in sample_faces:
    img_path = os.path.join(faces_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(1)

test_images = np.array(test_images)
test_labels = np.array(test_labels)
predictions = (model_MobileNetV2.predict(test_images) > 0.6).astype(int)

plt.figure(figsize=(15, 8))
for i in range(num_images_to_show):
    plt.subplot(1, num_images_to_show, i + 1)
    plt.imshow(test_images[i])

    true_label = test_labels[i]
    predicted_label = predictions[i][0]

    plt.title(f"True: {['Other', 'Selfie'][true_label]}\nPred: {['Other', 'Selfie'][predicted_label]}")
    plt.axis('off')

plt.tight_layout()
plt.show()

image_folder = "C:/Users/Anastasia/Downloads/Тестирование"
selfie_count = 0

for img_name in os.listdir(image_folder):
    if img_name.endswith(('png', 'jpg', 'jpeg', 'PNG')):
        img_path = os.path.join(image_folder, img_name)
        result = predict_face(img_path, model_MobileNetV2)
        if result == "Selfie":
            selfie_count += 1
print(f"Total 'Selfie' predictions: {selfie_count}")



"""### DenseNet121"""

DenseNet121 = tf.keras.applications.DenseNet121(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False, weights='imagenet')
DenseNet121.trainable = False

DenseNet121 = Sequential([
    DenseNet121,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')
])

DenseNet121.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
DenseNet121.summary()

start_time = time.time()
EPOCHS = 5
history = DenseNet121.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS
)

elapsed_time = time.time() - start_time
print(f"Время обучения: {elapsed_time} секунд")
test_loss, test_accuracy = DenseNet121.evaluate(test_generator)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")
DenseNet121.save("DenseNet121.keras")

predictions = (DenseNet121.predict(test_generator) > 0.5).astype(int)
true_labels = test_generator.classes

print("Classification Report:")
print(classification_report(true_labels, predictions, target_names=["Other", "Selfie"]))

cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, fmt='d', cmap='Blues', xticklabels=["Other", "Selfie"], yticklabels=["Other", "Selfie"])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

faces_folder = "C:/Users/Anastasia/Downloads/Бинарная/test/selfie"
random_objects_folder = "C:/Users/Anastasia/Downloads/Бинарная/test/other"
DenseNet121 = load_model("DenseNet121.keras")

face_images = [f for f in os.listdir(faces_folder) if f.endswith(('png', 'jpg', 'jpeg', '.PNG'))]
random_images = [f for f in os.listdir(random_objects_folder) if f.endswith(('png', 'jpg', 'jpeg', '.PNG'))]

num_images_to_show = 6
sample_faces = random.sample(face_images, num_images_to_show//2)
sample_random_objects = random.sample(random_images, num_images_to_show//2)

test_images = []
test_labels = []

for img_name in sample_random_objects:
    img_path = os.path.join(random_objects_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(0)

for img_name in sample_faces:
    img_path = os.path.join(faces_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(1)

test_images = np.array(test_images)
test_labels = np.array(test_labels)
predictions = (DenseNet121.predict(test_images) > 0.6).astype(int)

plt.figure(figsize=(15, 8))
for i in range(num_images_to_show):
    plt.subplot(1, num_images_to_show, i + 1)
    plt.imshow(test_images[i])

    true_label = test_labels[i]
    predicted_label = predictions[i][0]

    plt.title(f"True: {['Other', 'Selfie'][true_label]}\nPred: {['Other', 'Selfie'][predicted_label]}")
    plt.axis('off')

plt.tight_layout()
plt.show()

image_folder = "C:/Users/Anastasia/Downloads/Тестирование"
selfie_count = 0

for img_name in os.listdir(image_folder):
    if img_name.endswith(('png', 'jpg', 'jpeg', 'PNG')):
        img_path = os.path.join(image_folder, img_name)
        result = predict_face(img_path, DenseNet121)
        if result == "Selfie":
            selfie_count += 1
print(f"Total 'Selfie' predictions: {selfie_count}")



"""### InceptionV3"""

InceptionV3 = tf.keras.applications.InceptionV3(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False, weights='imagenet')
InceptionV3.trainable = False

InceptionV3 = Sequential([
    InceptionV3,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')
])

InceptionV3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
InceptionV3.summary()

start_time = time.time()
EPOCHS = 5
history = InceptionV3.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS
)

elapsed_time = time.time() - start_time
print(f"Время обучения: {elapsed_time} секунд")
test_loss, test_accuracy = InceptionV3.evaluate(test_generator)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")
InceptionV3.save("InceptionV3.keras")

predictions = (InceptionV3.predict(test_generator) > 0.5).astype(int)
true_labels = test_generator.classes

print("Classification Report:")
print(classification_report(true_labels, predictions, target_names=["Other", "Selfie"]))

cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, fmt='d', cmap='Blues', xticklabels=["Other", "Selfie"], yticklabels=["Other", "Selfie"])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

faces_folder = "C:/Users/Anastasia/Downloads/Бинарная/test/selfie"
random_objects_folder = "C:/Users/Anastasia/Downloads/Бинарная/test/other"
InceptionV3 = load_model("InceptionV3.keras")

face_images = [f for f in os.listdir(faces_folder) if f.endswith(('png', 'jpg', 'jpeg', '.PNG'))]
random_images = [f for f in os.listdir(random_objects_folder) if f.endswith(('png', 'jpg', 'jpeg', '.PNG'))]

num_images_to_show = 6
sample_faces = random.sample(face_images, num_images_to_show//2)
sample_random_objects = random.sample(random_images, num_images_to_show//2)

test_images = []
test_labels = []

for img_name in sample_random_objects:
    img_path = os.path.join(random_objects_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(0)

for img_name in sample_faces:
    img_path = os.path.join(faces_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(1)

test_images = np.array(test_images)
test_labels = np.array(test_labels)
predictions = (InceptionV3.predict(test_images) > 0.6).astype(int)

plt.figure(figsize=(15, 8))
for i in range(num_images_to_show):
    plt.subplot(1, num_images_to_show, i + 1)
    plt.imshow(test_images[i])

    true_label = test_labels[i]
    predicted_label = predictions[i][0]

    plt.title(f"True: {['Other', 'Selfie'][true_label]}\nPred: {['Other', 'Selfie'][predicted_label]}")
    plt.axis('off')

plt.tight_layout()
plt.show()

image_folder = "C:/Users/Anastasia/Downloads/Тестирование"
selfie_count = 0

for img_name in os.listdir(image_folder):
    if img_name.endswith(('png', 'jpg', 'jpeg', 'PNG')):
        img_path = os.path.join(image_folder, img_name)
        result = predict_face(img_path, InceptionV3)
        if result == "Selfie":
            selfie_count += 1
print(f"Total 'Selfie' predictions: {selfie_count}")

"""### My CNN"""

my_model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(256, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

my_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
my_model.summary()

start_time = time.time()
EPOCHS = 11
history_3 = my_model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS
)

elapsed_time = time.time() - start_time
print(f"Время обучения: {elapsed_time} секунд")
test_loss, test_accuracy = my_model.evaluate(test_generator)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")

my_model.save("my_model.keras")

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history_3.history['loss'], label='Train Loss')
plt.plot(history_3.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss over Epochs')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_3.history['accuracy'], label='Train Accuracy')
plt.plot(history_3.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy over Epochs')
plt.legend()
plt.tight_layout()
plt.show()

predictions = (my_model.predict(test_generator) > 0.6).astype(int)
true_labels = test_generator.classes

print("Classification Report:")
print(classification_report(true_labels, predictions, target_names=["Other", "Selfie"]))

cm = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, fmt='d', cmap='Blues', xticklabels=["Other", "Selfie"], yticklabels=["Other", "Selfie"])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

faces_folder = "C:/Users/Anastasia/Downloads/Бинарная/test/selfie"
random_objects_folder = "C:/Users/Anastasia/Downloads/Бинарная/test/other"
my_model = load_model("my_model.keras")

face_images = [f for f in os.listdir(faces_folder) if f.endswith(('png', 'jpg', 'jpeg', '.PNG'))]
random_images = [f for f in os.listdir(random_objects_folder) if f.endswith(('png', 'jpg', 'jpeg', '.PNG'))]

num_images_to_show = 6
sample_faces = random.sample(face_images, num_images_to_show//2)
sample_random_objects = random.sample(random_images, num_images_to_show//2)

test_images = []
test_labels = []

for img_name in sample_random_objects:
    img_path = os.path.join(random_objects_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(0)

for img_name in sample_faces:
    img_path = os.path.join(faces_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(1)

test_images = np.array(test_images)
test_labels = np.array(test_labels)
predictions = (my_model.predict(test_images) > 0.6).astype(int)

plt.figure(figsize=(15, 8))
for i in range(num_images_to_show):
    plt.subplot(1, num_images_to_show, i + 1)
    plt.imshow(test_images[i])

    true_label = test_labels[i]
    predicted_label = predictions[i][0]

    plt.title(f"True: {['Other', 'Selfie'][true_label]}\nPred: {['Other', 'Selfie'][predicted_label]}")
    plt.axis('off')

plt.tight_layout()
plt.show()

image_folder = "C:/Users/Anastasia/Downloads/Тестирование"
selfie_count = 0

for img_name in os.listdir(image_folder):
    if img_name.endswith(('png', 'jpg', 'jpeg', 'PNG')):
        img_path = os.path.join(image_folder, img_name)
        result = predict_face(img_path, my_model)
        if result == "Selfie":
            selfie_count += 1
print(f"Total 'Selfie' predictions: {selfie_count}")







"""## Множественная классификация"""

#DATASET_DIR = "C:/Users/Anastasia/Downloads/датасет диплом/Бинарная/"
TRAIN_DIR = "C:/Users/Anastasia/Downloads/Множественная/train"
VALID_DIR = "C:/Users/Anastasia/Downloads/Множественная/val"
TEST_DIR = "C:/Users/Anastasia/Downloads/Множественная/test"

IMG_HEIGHT, IMG_WIDTH = 128, 128
BATCH_SIZE = 32

train_datagen = ImageDataGenerator(rescale=1./255,
                                   rotation_range=20,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True)
validation_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    TRAIN_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='categorical')

validation_generator = validation_datagen.flow_from_directory(
    VALID_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='categorical')

test_generator = test_datagen.flow_from_directory(
    TEST_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=1, class_mode='categorical', shuffle=False)

classes = list(train_generator.class_indices.keys())
classes

"""### DenseNet121"""

base_model_DenseNet121 = tf.keras.applications.DenseNet121(
    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),
    include_top=False,
    weights='imagenet'
)
base_model_DenseNet121.trainable = False

model_DenseNet121 = Sequential([
    base_model_DenseNet121,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(3, activation='softmax')  # 3 класса
])

model_DenseNet121.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model_DenseNet121.summary()

start_time = time.time()
EPOCHS = 8
history = model_DenseNet121.fit(train_generator, validation_data=validation_generator, epochs=EPOCHS)
elapsed_time = time.time() - start_time
print(f"Время обучения: {elapsed_time:.2f} секунд")
test_loss, test_accuracy = model_DenseNet121.evaluate(test_generator)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")
model_DenseNet121.save("DenseNet121_multi_class.keras")

predictions = model_DenseNet121.predict(test_generator)
predictions_classes = np.argmax(predictions, axis=1)
true_labels = test_generator.classes

print("Classification Report:")
print(classification_report(true_labels, predictions_classes, target_names=["Visual Attack", "Other", "Selfie"]))

cm = confusion_matrix(true_labels, predictions_classes)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, fmt='d', cmap='Blues', xticklabels=["Visual Attack", "Other", "Selfie"], yticklabels=["Visual Attack", "Other", "Selfie"])
plt.xlabel('Предсказанные метки')
plt.ylabel('Истинные метки')
plt.title('Матрица')
plt.style.use('_classic_test_patch')
plt.show()

faces_folder = "C:/Users/Anastasia/Downloads/Множественная/test/selfie"
visual_attack_folder = "C:/Users/Anastasia/Downloads/Множественная/test/attack"
random_objects_folder = "C:/Users/Anastasia/Downloads/Множественная/test/other"

model_DenseNet121 = load_model("DenseNet121_multi_class.keras")

face_images = [f for f in os.listdir(faces_folder) if f.endswith(('png', 'jpg', 'jpeg', 'PNG'))]
visual_attack_images = [f for f in os.listdir(visual_attack_folder) if f.endswith(('png', 'jpg', 'jpeg', 'PNG'))]
random_images = [f for f in os.listdir(random_objects_folder) if f.endswith(('png', 'jpg', 'jpeg', 'PNG'))]

num_images_to_show = 6
sample_faces = random.sample(face_images, num_images_to_show // 3)
sample_visual_attacks = random.sample(visual_attack_images, num_images_to_show // 3)
sample_random_objects = random.sample(random_images, num_images_to_show // 3)

test_images = []
test_labels = []

for img_name in sample_visual_attacks:
    img_path = os.path.join(visual_attack_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(0)  # 0 - attack

for img_name in sample_random_objects:
    img_path = os.path.join(random_objects_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(1)  # 1 - Other

for img_name in sample_faces:
    img_path = os.path.join(faces_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(2)  # 2 - Selfie


test_images = np.array(test_images)
test_labels = np.array(test_labels)

predictions = model_DenseNet121.predict(test_images)
predicted_classes = np.argmax(predictions, axis=1)

plt.figure(figsize=(15, 8))
for i in range(num_images_to_show):
    plt.subplot(1, num_images_to_show, i + 1)
    plt.imshow(test_images[i])
    true_label = test_labels[i]
    predicted_label = predicted_classes[i]
    plt.title(f"True: {['Visual Attack', 'Other', 'Selfie'][true_label]}\nPred: {['Visual Attack', 'Other', 'Selfie'][predicted_label]}")
    plt.axis('off')

plt.tight_layout()
plt.show()



"""### MobileNetV2"""

base_model_MobileNetV2 = tf.keras.applications.MobileNetV2(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False, weights='imagenet')
base_model_MobileNetV2.trainable = False

model_MobileNetV2 = Sequential([
    base_model_MobileNetV2,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(3, activation='softmax')
])

model_MobileNetV2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model_MobileNetV2.summary()

start_time = time.time()
EPOCHS = 8
history = model_MobileNetV2.fit(train_generator, validation_data=validation_generator, epochs=EPOCHS)
elapsed_time = time.time() - start_time
print(f"Время обучения: {elapsed_time:.2f} секунд")
test_loss, test_accuracy = model_MobileNetV2.evaluate(test_generator)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")
model_MobileNetV2.save("model_MobileNetV2.keras")

predictions = model_MobileNetV2.predict(test_generator)
predictions_classes = np.argmax(predictions, axis=1)
true_labels = test_generator.classes

print("Classification Report:")
print(classification_report(true_labels, predictions_classes, target_names=["Visual Attack", "Other", "Selfie"]))

cm = confusion_matrix(true_labels, predictions_classes)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, fmt='d', cmap='Blues', xticklabels=["Visual Attack", "Other", "Selfie"], yticklabels=["Visual Attack", "Other", "Selfie"])
plt.xlabel('Предсказанные метки')
plt.ylabel('Истинные метки')
plt.title('Матрица')
plt.show()

faces_folder = "C:/Users/Anastasia/Downloads/Множественная/test/selfie"
visual_attack_folder = "C:/Users/Anastasia/Downloads/Множественная/test/attack"
random_objects_folder = "C:/Users/Anastasia/Downloads/Множественная/test/other"

model_MobileNetV2 = load_model("model_MobileNetV2.keras")

face_images = [f for f in os.listdir(faces_folder) if f.endswith(('png', 'jpg', 'jpeg', 'PNG'))]
visual_attack_images = [f for f in os.listdir(visual_attack_folder) if f.endswith(('png', 'jpg', 'jpeg', 'PNG'))]
random_images = [f for f in os.listdir(random_objects_folder) if f.endswith(('png', 'jpg', 'jpeg', 'PNG'))]

num_images_to_show = 6
sample_faces = random.sample(face_images, num_images_to_show // 3)
sample_visual_attacks = random.sample(visual_attack_images, num_images_to_show // 3)
sample_random_objects = random.sample(random_images, num_images_to_show // 3)

test_images = []
test_labels = []

for img_name in sample_visual_attacks:
    img_path = os.path.join(visual_attack_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(0)  # 0 - attack

for img_name in sample_random_objects:
    img_path = os.path.join(random_objects_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(1)  # 1 - Other

for img_name in sample_faces:
    img_path = os.path.join(faces_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(2)  # 2 - Selfie


test_images = np.array(test_images)
test_labels = np.array(test_labels)

predictions = model_MobileNetV2.predict(test_images)
predicted_classes = np.argmax(predictions, axis=1)

plt.figure(figsize=(15, 8))
for i in range(num_images_to_show):
    plt.subplot(1, num_images_to_show, i + 1)
    plt.imshow(test_images[i])
    true_label = test_labels[i]
    predicted_label = predicted_classes[i]
    plt.title(f"True: {['Visual Attack', 'Other', 'Selfie'][true_label]}\nPred: {['Visual Attack', 'Other', 'Selfie'][predicted_label]}")
    plt.axis('off')

plt.tight_layout()
plt.show()



"""### InceptionV3"""

InceptionV3 = tf.keras.applications.InceptionV3(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False, weights='imagenet')
InceptionV3.trainable = False

InceptionV3 = Sequential([
    InceptionV3,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(3, activation='softmax')
])

InceptionV3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
InceptionV3.summary()

start_time = time.time()
EPOCHS = 10
history = InceptionV3.fit(train_generator, validation_data=validation_generator, epochs=EPOCHS)
elapsed_time = time.time() - start_time
print(f"Время обучения: {elapsed_time:.2f} секунд")
test_loss, test_accuracy = InceptionV3.evaluate(test_generator)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")
InceptionV3.save("InceptionV3.keras")

predictions = InceptionV3.predict(test_generator)
predictions_classes = np.argmax(predictions, axis=1)
true_labels = test_generator.classes

print("Classification Report:")
print(classification_report(true_labels, predictions_classes, target_names=["Visual Attack", "Other", "Selfie"]))

cm = confusion_matrix(true_labels, predictions_classes)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, fmt='d', cmap='Blues', xticklabels=["Visual Attack", "Other", "Selfie"], yticklabels=["Visual Attack", "Other", "Selfie"])
plt.xlabel('Предсказанные метки')
plt.ylabel('Истинные метки')
plt.title('Матрица')
plt.show()

faces_folder = "C:/Users/Anastasia/Downloads/Множественная/test/selfie"
visual_attack_folder = "C:/Users/Anastasia/Downloads/Множественная/test/attack"
random_objects_folder = "C:/Users/Anastasia/Downloads/Множественная/test/other"

InceptionV3 = load_model("InceptionV3.keras")

face_images = [f for f in os.listdir(faces_folder) if f.endswith(('png', 'jpg', 'jpeg', 'PNG'))]
visual_attack_images = [f for f in os.listdir(visual_attack_folder) if f.endswith(('png', 'jpg', 'jpeg', 'PNG'))]
random_images = [f for f in os.listdir(random_objects_folder) if f.endswith(('png', 'jpg', 'jpeg', 'PNG'))]

num_images_to_show = 6
sample_faces = random.sample(face_images, num_images_to_show // 3)
sample_visual_attacks = random.sample(visual_attack_images, num_images_to_show // 3)
sample_random_objects = random.sample(random_images, num_images_to_show // 3)

test_images = []
test_labels = []

for img_name in sample_visual_attacks:
    img_path = os.path.join(visual_attack_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(0)  # 0 - attack

for img_name in sample_random_objects:
    img_path = os.path.join(random_objects_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(1)  # 1 - Other

for img_name in sample_faces:
    img_path = os.path.join(faces_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(2)  # 2 - Selfie


test_images = np.array(test_images)
test_labels = np.array(test_labels)

predictions = InceptionV3.predict(test_images)
predicted_classes = np.argmax(predictions, axis=1)

plt.figure(figsize=(15, 8))
for i in range(num_images_to_show):
    plt.subplot(1, num_images_to_show, i + 1)
    plt.imshow(test_images[i])
    true_label = test_labels[i]
    predicted_label = predicted_classes[i]
    plt.title(f"True: {['Visual Attack', 'Other', 'Selfie'][true_label]}\nPred: {['Visual Attack', 'Other', 'Selfie'][predicted_label]}")
    plt.axis('off')

plt.tight_layout()
plt.show()











"""### Попытка улучшения"""

from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import regularizers

base_model_DenseNet121 = tf.keras.applications.DenseNet121(
    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),
    include_top=False,
    weights='imagenet'
)
base_model_DenseNet121.trainable = False

model_DenseNet121_try = Sequential([
    base_model_DenseNet121,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.005)),
    Dropout(0.5),
    Dense(3, activation='softmax', kernel_regularizer=regularizers.l2(0.005))  # 3 класса
])

model_DenseNet121_try.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model_DenseNet121_try.summary()

early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

start_time = time.time()
EPOCHS = 12
history = model_DenseNet121_try.fit(train_generator, validation_data=validation_generator, epochs=EPOCHS, callbacks=[early_stopping])
elapsed_time = time.time() - start_time
print(f"Время обучения: {elapsed_time:.2f} секунд")
test_loss, test_accuracy = model_DenseNet121_try.evaluate(test_generator)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")
model_DenseNet121_try.save("model_DenseNet121_try.keras")

predictions = model_DenseNet121_try.predict(test_generator)
predictions_classes = np.argmax(predictions, axis=1)
true_labels = test_generator.classes

print("Classification Report:")
print(classification_report(true_labels, predictions_classes, target_names=["Visual Attack", "Other", "Selfie"]))

cm = confusion_matrix(true_labels, predictions_classes)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, fmt='d', cmap='Blues', xticklabels=["Visual Attack", "Other", "Selfie"], yticklabels=["Visual Attack", "Other", "Selfie"])
plt.xlabel('Предсказанные метки')
plt.ylabel('Истинные метки')
plt.title('Матрица')
plt.show()

faces_folder = "C:/Users/Anastasia/Downloads/Множественная/test/selfie"
visual_attack_folder = "C:/Users/Anastasia/Downloads/Множественная/test/attack"
random_objects_folder = "C:/Users/Anastasia/Downloads/Множественная/test/other"

model_DenseNet121_try = load_model("model_DenseNet121_try.keras")

face_images = [f for f in os.listdir(faces_folder) if f.endswith(('png', 'jpg', 'jpeg', 'PNG'))]
visual_attack_images = [f for f in os.listdir(visual_attack_folder) if f.endswith(('png', 'jpg', 'jpeg', 'PNG'))]
random_images = [f for f in os.listdir(random_objects_folder) if f.endswith(('png', 'jpg', 'jpeg', 'PNG'))]

num_images_to_show = 6
sample_faces = random.sample(face_images, num_images_to_show // 3)
sample_visual_attacks = random.sample(visual_attack_images, num_images_to_show // 3)
sample_random_objects = random.sample(random_images, num_images_to_show // 3)

test_images = []
test_labels = []

for img_name in sample_visual_attacks:
    img_path = os.path.join(visual_attack_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(0)  # 0 - attack

for img_name in sample_random_objects:
    img_path = os.path.join(random_objects_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(1)  # 1 - Other

for img_name in sample_faces:
    img_path = os.path.join(faces_folder, img_name)
    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
    img_array = image.img_to_array(img) / 255.0
    test_images.append(img_array)
    test_labels.append(2)  # 2 - Selfie


test_images = np.array(test_images)
test_labels = np.array(test_labels)

predictions = model_DenseNet121_try.predict(test_images)
predicted_classes = np.argmax(predictions, axis=1)

plt.figure(figsize=(15, 8))
for i in range(num_images_to_show):
    plt.subplot(1, num_images_to_show, i + 1)
    plt.imshow(test_images[i])
    true_label = test_labels[i]
    predicted_label = predicted_classes[i]
    plt.title(f"True: {['Visual Attack', 'Other', 'Selfie'][true_label]}\nPred: {['Visual Attack', 'Other', 'Selfie'][predicted_label]}")
    plt.axis('off')

plt.tight_layout()
plt.show()



"""## Выбор детектора

### YuNet
"""

def show_YuNet_face_detecor(image_path , image_number=1):
    started_time = time.time()
    print('Детектор - YuNet  ')
    plt.style.use('dark_background')
    plt.figure(figsize=(18, 8))
    plt.suptitle('Детектор YuNet')
    plt.subplot(1 , 2, 1)
    original_image = plt.imread(image_path)
    print(f'Размер изображения: {original_image.shape[:2]}')
    plt.imshow(original_image)
    plt.axis('off')
    plt.subplot(1 , 2 , 2)
    image = cv2.imread(image_path)
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    detector = cv2.FaceDetectorYN.create("C:/Users/Anastasia/Downloads/face_detection_yunet_2023mar.onnx", "", (320, 320))
    img_W = int(image.shape[1])
    img_H = int(image.shape[0])
    detector.setInputSize((img_W, img_H))
    detections = detector.detect(image)
    if detections is not None:
        detected_faces = detections[1]
        for face in detected_faces:
            x, y, width, height = face[:4]
            x1, y1 = int(x), int(y)
            x2, y2 = int(x + width), int(y + height)
            cv2.rectangle(rgb_image, (x1, y1), (x2, y2), (255, 0, 0), 2)
            conf = face[14]
            #cv2.putText(image, f'{conf:.1f}', (x1, y1 - 10),
                        #cv2.FONT_HERSHEY_SIMPLEX, 0.5, ( 0 , 0, 255), 2)

    else:
        print(f'There is no detected faces in the image number {i}')

    rgb_image_back = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    print(f'Количество детектированных объектов: {len(detections[1])} из 225 возможных')
    plt.imshow(rgb_image)
    plt.axis('off')
    end_time = time.time()
    print(f'Время обработки : {end_time - started_time}')
show_YuNet_face_detecor("./ppp.JPG")

"""### Haar"""

def show_Haar_face_detecor(image_path , image_number=1):
    started_time = time.time()
    print('Детектор - Каскад Хаара  ')
    plt.style.use('dark_background')
    plt.figure(figsize=(18, 8))
    plt.suptitle('Детектор Каскад Хаара')
    plt.subplot(1 , 2, 1)
    original_image = plt.imread(image_path)
    print(f'Размер изображения: {original_image.shape[:2]}')
    plt.imshow(original_image)
    plt.axis('off')
    plt.subplot(1 , 2 , 2)
    image = cv2.imread(image_path)
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image_gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    detections = face_cascade.detectMultiScale(image_gray, scaleFactor=1.1, minNeighbors=5)
    if detections is not None:
        for (x, y, w, h) in detections:
            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)
    else:
        print(f'There is no detected faces in the image number {i}')

    rgb_image_back = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    print(f'Количество детектированных объектов: {len(detections)} из 225 возможных')
    plt.imshow(rgb_image_back)
    plt.axis('off')
    end_time = time.time()
    print(f'Время обработки : {end_time - started_time}')
    plt.show()
show_Haar_face_detecor("./ppp.JPG")



"""### MTCNN"""

def show_MTCNN_face_detecor(image_path , image_number=1):
    started_time = time.time()
    print('Детектор - MTCNN  ')
    plt.style.use('dark_background')
    plt.figure(figsize=(18, 8))
    plt.suptitle('Детектор MTCNN')
    plt.subplot(1 , 2, 1)
    original_image = plt.imread(image_path)
    print(f'Размер изображения: {original_image.shape[:2]}')
    plt.imshow(original_image)
    plt.axis('off')
    plt.subplot(1 , 2 , 2)
    image = cv2.imread(image_path)
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    detector = MTCNN()
    faces = detector.detect_faces(image)
    if faces is not None:
        for face in faces:
            x, y, width, height = face['box']
            cv2.rectangle(rgb_image, (x, y), (x + width, y + height), (255, 0,0), 2)
    else:
        print(f'There is no detected faces in the image number {i}')

    print(f'Количество детектированных объектов: {len(faces)} из 225 возможных')
    plt.imshow(rgb_image)
    plt.axis('off')
    end_time = time.time()
    print(f'Время обработки : {end_time - started_time}')
    plt.show()
show_MTCNN_face_detecor("./ppp.JPG")





"""## Реализация главной функции

### Без эталонного фото
"""

model = load_model("model_DenseNet121_try.keras")
detector = MTCNN()

correct_password = "1111"
max_attempts = 5

def detect_faces(image_path):
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    detector = MTCNN()
    faces = detector.detect_faces(image_rgb)
    for face in faces:
        x, y, width, height = face['box']
        cv2.rectangle(image_rgb, (x, y), (x + width, y + height), (255, 0, 0), 2)

    plt.figure(figsize=(10, 10))
    plt.imshow(image_rgb)
    plt.axis('off')
    plt.show()


def classify_image(image):
    if image is None:
        print("Ошибка: изображение не загружено.")
        return None

    image = cv2.resize(image, (128, 128))
    image = np.expand_dims(image, axis=0) / 255.0
    predictions = model.predict(image)
    predicted_class = np.argmax(predictions)
    return predicted_class

def main():
    flag = True
    while flag == True:
        img_path = input("Введите путь к фотографии (или 'q' для выхода): ")

        if img_path.lower() == 'q':
            print("Закрытие программы.")
            break

        image = cv2.imread(img_path)
        if image is None:
            print("Ошибка при загрузке фотографии. Проверьте путь и формат файла.")
            continue

        predicted_class = classify_image(image)


        if predicted_class == 0:
            print("Похоже, кто-то пытается войти в ваш аккаунт! \nСрочно смените пароль от своей учетной записи")
            flag = False

        elif predicted_class == 1:
            print("Не удается распознать лицо. \nПожалуйста, загрузите фотографию еще раз.")

        elif predicted_class == 2:
            print("Лицо обнаружено")
            faces = detect_faces(f'{img_path}')

            attempts = 0
            while attempts < max_attempts:
                password = input("Пожалуйста, введите ваш пароль: ")
                if password == correct_password:
                    print("Вход в аккаунт выполнен успешно!")
                    return
                else:
                    attempts += 1
                    print(f"Неверный пароль. Вы можете попробовать еще раз ({max_attempts - attempts} попытки осталось).")

            print("Доступ заморожен на 15 минут. Пожалуйста, подождите...")
            flag = False


if __name__ == "__main__":
    main()

if __name__ == "__main__":
    main()





"""### С эталонным фото"""

!pip install keras_facenet

from keras_facenet import FaceNet
from sklearn.metrics.pairwise import cosine_similarity

class FaceRecognitionSystem:
    def __init__(self, model_path, reference_image_path, correct_password, max_attempts, threshold=0.5):
        """
        Инициализация системы распознавания лиц.

        Args:
            model_path (str): Путь к модели классификации изображений.
            reference_image_path (str): Путь к эталонному изображению лица.
            correct_password (str): Правильный пароль для входа.
            max_attempts (int): Максимальное количество попыток ввода пароля.
            threshold (float): Порог косинусной близости для распознавания лиц.
        """
        self.model = load_model(model_path)
        self.detector = MTCNN()
        self.embedder = FaceNet()
        self.correct_password = correct_password
        self.max_attempts = max_attempts
        self.threshold = threshold
        self.reference_embedding = self.get_embedding(reference_image_path)

    def detect_faces(self, image_path):
        """
        Обнаруживает лица на изображении и отображает результат с прямоугольниками.

        Args:
            image_path (str): Путь к изображению.
        """
        image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        faces = self.detector.detect_faces(image_rgb)

        for face in faces:
            x, y, width, height = face['box']
            cv2.rectangle(image_rgb, (x, y), (x + width, y + height), (255, 0, 0), 2)

        plt.figure(figsize=(10, 10))
        plt.imshow(image_rgb)
        plt.axis('off')
        plt.show()

    def classify_image(self, image):
        """
        Классифицирует изображение с использованием предварительно обученной модели.

        Args:
            image (np.ndarray): Изображение для классификации.

        Returns:
            int: Индекс предсказанного класса.
        """
        if image is None:
            print("Ошибка: изображение не загружено.")
            return None

        image = cv2.resize(image, (128, 128))
        image = np.expand_dims(image, axis=0) / 255.0
        predictions = self.model.predict(image)
        predicted_class = np.argmax(predictions)
        return predicted_class

    def get_embedding(self, image_path):
        """
        Получает эмбеддинг лица из изображения с использованием FaceNet.

        Args:
            image_path (str): Путь к изображению.

        Returns:
            np.ndarray: Эмбеддинг лица.
        """
        image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        faces = self.detector.detect_faces(image_rgb)

        if len(faces) == 0:
            raise ValueError("No face detected in reference image")

        x, y, width, height = faces[0]['box']
        x1, y1 = abs(x), abs(y)
        x2, y2 = x1 + width, y1 + height
        face_image = image[y1:y2, x1:x2]
        face_image = face_image.astype('float32')

        embedding = self.embedder.embeddings([face_image])
        return embedding[0]

    def compare_embeddings(self, user_embedding):
        """
        Сравнивает эмбеддинг пользователя с эталонным эмбеддингом.

        Args:
            user_embedding (np.ndarray): Эмбеддинг лица пользователя.

        Returns:
            tuple: (bool, float) - (Является ли лицо совпадением, оценка сходства).
        """
        similarity = cosine_similarity([self.reference_embedding], [user_embedding])[0, 0]
        return similarity >= self.threshold, similarity

    def authenticate(self, img_path):
        """
        Основная функция для аутентификации пользователя.

        Args:
            img_path (str): Путь к фотографии пользователя.
        """

        if not os.path.exists(img_path):
            print("Ошибка: Файл не существует. Проверьте путь.")
            return True

        try:
            image = cv2.imread(img_path)
            if image is None:
                print("Ошибка при загрузке фотографии. Проверьте путь и формат файла.")
                return True

            predicted_class = self.classify_image(image)

            if predicted_class == 0:
                print("Похоже, кто-то пытается войти в Ваш аккаунт! \nСрочно смените пароль от своей учетной записи")
                return False

            elif predicted_class == 1:
                print("Не удается распознать лицо. \nПожалуйста, загрузите фотографию еще раз.")
                return True

            elif predicted_class == 2:
                picture = self.detect_faces(img_path)
                user_embedding = self.get_embedding(img_path)
                is_match, similarity_score = self.compare_embeddings(user_embedding)
                if is_match:
                    print(f"Лицо успешно распозналось! (Сходство: {similarity_score:.4f})")
                    attempts = 0
                    while attempts < self.max_attempts:
                        password = input("Пожалуйста, введите ваш пароль: ")
                        if password == self.correct_password:
                            print("Вход в аккаунт выполнен успешно!")
                            return False
                        else:
                            attempts += 1
                            print(f"Неверный пароль. Вы можете попробовать еще раз ({self.max_attempts - attempts} попытки осталось).")


                    print("Доступ заморожен на 15 минут. Пожалуйста, подождите...")
                    return False
                else:
                    print(f"Маленькая степень сходства.(Сходство: {similarity_score:.4f}) \nКто-то пытыается войти в Ваш аккаунт. \nСрочно смените пароль от своей учетной записи")
                    return False
            return True

        except Exception as e:
            print(f"Произошла общая ошибка: {e}")
            return True

    def run(self):
        """
        Запускает основной цикл программы.
        """
        while True:
            img_path = input("Введите путь к фотографии (или 'q' для выхода): ")

            if img_path.lower() == 'q':
                print("Закрытие программы.")
                break

            if not self.authenticate(img_path):
                break

if __name__ == "__main__":
    model_path = "model_DenseNet121_try.keras"
    reference_image_path = "C:/Users/Anastasia/Downloads/Telegram Desktop/my_photos/my_etalon (19).JPG"
    correct_password = "1111"
    max_attempts = 5

    face_recognition_system = FaceRecognitionSystem(model_path, reference_image_path, correct_password, max_attempts)
    face_recognition_system.run()

if __name__ == "__main__":
    model_path = "model_DenseNet121_try.keras"
    reference_image_path = "C:/Users/Anastasia/Downloads/Telegram Desktop/my_photos/my_etalon (19).JPG"
    correct_password = "1111"
    max_attempts = 5

    face_recognition_system = FaceRecognitionSystem(model_path, reference_image_path, correct_password, max_attempts)
    face_recognition_system.run()

C:/Users/Anastasia/Downloads/Множественная/train

if __name__ == "__main__":
    model_path = "model_DenseNet121_try.keras"
    reference_image_path = "C:/Users/Anastasia/Downloads/Telegram Desktop/my_photos/my_etalon (19).JPG"
    correct_password = "1111"
    max_attempts = 5

    face_recognition_system = FaceRecognitionSystem(model_path, reference_image_path, correct_password, max_attempts)
    face_recognition_system.run()

